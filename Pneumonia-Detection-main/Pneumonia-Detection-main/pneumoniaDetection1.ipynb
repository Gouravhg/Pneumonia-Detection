{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1423e2e-e446-4875-8168-66ff4ee5a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110119c3-8773-458a-bd0c-af323f0cb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"archive/chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230be9b-5637-45b4-817c-c640f90ccb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samplesize = pd.DataFrame.from_dict(\n",
    "    {'Normal': [len([os.path.join(path+'/train/NORMAL', filename) \n",
    "                     for filename in os.listdir(path+'/train/NORMAL')])], \n",
    "     'Pneumonia': [len([os.path.join(path+'/train/PNEUMONIA', filename) \n",
    "                        for filename in os.listdir(path+'/train/PNEUMONIA')])]})\n",
    "\n",
    "\n",
    "sns.barplot(data=train_samplesize).set_title('Training Set Data Inbalance', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287efa4-30a8-443b-b6f7-382a20f7b478",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281818b7-80fd-4677-bb56-b65682613e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = {\n",
    "    'dataset1': transform.Compose([transform.Resize(255),\n",
    "                                            transform.CenterCrop(224),\n",
    "                                            transform.RandomHorizontalFlip(),\n",
    "                                            transform.RandomRotation(10),\n",
    "                                            transform.RandomGrayscale(),\n",
    "                                            transform.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                            transform.ToTensor()\n",
    "                                           ]),\n",
    "        \n",
    "    'dataset2' : transform.Compose([transform.Resize(255),\n",
    "                                            transform.CenterCrop(224),\n",
    "                                            transform.RandomHorizontalFlip(p=1),\n",
    "                                            transform.RandomGrayscale(),\n",
    "                                            transform.RandomAffine(translate=(0.1,0.05), degrees=10),\n",
    "                                            transform.ToTensor()\n",
    "                                    \n",
    "                                           ]),\n",
    "    \n",
    "    'dataset3' : transform.Compose([transform.Resize(255),\n",
    "                                            transform.CenterCrop(224),\n",
    "                                            transform.RandomHorizontalFlip(p=0.5),\n",
    "                                            transform.RandomRotation(15),\n",
    "                                            transform.RandomGrayscale(p=1),\n",
    "                                            transform.RandomAffine(translate=(0.08,0.1), degrees=15),\n",
    "                                            transform.ToTensor()\n",
    "                                           ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4033f36-681b-4383-b047-ded53a762e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = ImageFolder(path+'/train', \n",
    "                      transform=transformer['dataset1'])\n",
    "\n",
    "dataset2 = ImageFolder(path+'/train', \n",
    "                      transform=transformer['dataset2'])\n",
    "\n",
    "dataset3 = ImageFolder(path+'/train', \n",
    "                      transform=transformer['dataset3'])\n",
    "\n",
    "norm1, _ = train_test_split(dataset2, test_size= 3875/(1341+3875), shuffle=False)\n",
    "norm2, _ = train_test_split(dataset3, test_size= 4023/(1341+3875), shuffle=False)\n",
    "\n",
    "dataset = ConcatDataset([dataset1, norm1, norm2])\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fa519-0b78-46fb-9b5d-218078512771",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset1.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e2938-5acb-45b8-8951-5a3330bb957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(samples):  \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,8))\n",
    "    for i in range(len(samples)):\n",
    "        image = cv2.cvtColor(imread(samples[i]), cv2.COLOR_BGR2RGB)\n",
    "        ax[i//5][i%5].imshow(image)\n",
    "        if i<5:\n",
    "            ax[i//5][i%5].set_title(\"Normal\", fontsize=20)\n",
    "        else:\n",
    "            ax[i//5][i%5].set_title(\"Pneumonia\", fontsize=20)\n",
    "        ax[i//5][i%5].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e392a-8d37-4736-adc8-62431316ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_samples = random.sample([os.path.join(path+'/train/NORMAL', filename) \n",
    "                              for filename in os.listdir(path+'/train/NORMAL')], 5) + \\\n",
    "    random.sample([os.path.join(path+'/train/PNEUMONIA', filename) \n",
    "                   for filename in os.listdir(path+'/train/PNEUMONIA')], 5)\n",
    "\n",
    "plot_samples(rand_samples)\n",
    "plt.suptitle('Training Set Samples', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdd4f0-6d90-4e7b-a468-87daa61626b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2020\n",
    "torch.manual_seed(random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6081d-92a4-4842-8075-7af416590756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = train_test_split(dataset, test_size=0.3, random_state=random_seed)\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a5713-c468-4de7-bdaf-0dfa6013312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "loaders = {'train':train_dl, 'val':val_dl}\n",
    "dataset_sizes = {'train':len(train_ds), 'val':len(val_ds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb081e3b-0aa3-4e97-9bb1-40eb2a873ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:60], nrow=10).permute(1, 2, 0))\n",
    "        break\n",
    "        \n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f04066-9f64-4507-913d-e52f62162ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) \n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1450ca-a69b-4f24-bb17-72e5406cf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97228f0a-d337-4f4e-bf73-55070d7282de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features = model.classifier.in_features\n",
    "\n",
    "model.classifier = nn.Linear(in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109778f-b57d-4e2c-ac79-8f4fa0aa23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'train':[], 'val':[]}\n",
    "accuracies = {'train':[], 'val':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709dbd9c-1793-439c-bbbe-b2f40fa3ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, epochs):\n",
    "  since = time.time()\n",
    "  best_model = copy.deepcopy(model.state_dict())\n",
    "  best_acc = 0.0\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      running_loss = 0.0\n",
    "      running_corrects = 0.0\n",
    "\n",
    "      for inputs, labels in loaders[phase]:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "          outp = model(inputs)\n",
    "          _, pred = torch.max(outp, 1)\n",
    "          loss = criterion(outp, labels)\n",
    "        \n",
    "          if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_corrects += torch.sum(pred == labels.data)\n",
    "          \n",
    "      epoch_loss = running_loss / dataset_sizes[phase]\n",
    "      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "      losses[phase].append(epoch_loss)\n",
    "      accuracies[phase].append(epoch_acc)\n",
    "      if phase == 'train':\n",
    "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n",
    "    \n",
    "      if phase == 'val':\n",
    "        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
    "            \n",
    "      if phase == 'val' and epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    scheduler.step()  \n",
    "  time_elapsed = time.time() - since\n",
    "  print('Training Time {}m {}s'.format(time_elapsed//60, time_elapsed%60)) \n",
    "  print('Best accuracy {}'.format(best_acc))\n",
    "\n",
    "  model.load_state_dict(best_model)\n",
    "  return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609909f3-4c1d-4afd-a827-292918ead97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77005121-1d13-454b-87f1-01717bb54373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "epochs = 10\n",
    "model = train(model, criterion, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6353e44-db28-4ac1-9085-9e6577bf9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "model.to(device)\n",
    "grad_clip = None\n",
    "weight_decay = 1e-4\n",
    "# weighted loss for data class imbalance\n",
    "epochs = 10\n",
    "model = train(model, criterion, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aef41-36bb-480a-8a8f-65fccf35c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,epochs*2+1))\n",
    "ax1.plot(epoch_list, accuracies['train'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, accuracies['val'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, epochs*2+1, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, losses['train'], label='Train Loss')\n",
    "ax2.plot(epoch_list, losses['val'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, epochs*2+1, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde1996-c38a-4946-afd3-e597f0d1f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samplesize = pd.DataFrame.from_dict(\n",
    "    {'Normal': [len([os.path.join(path+'/test/NORMAL', filename) \n",
    "                     for filename in os.listdir(path+'/test/NORMAL')])], \n",
    "     'Pneumonia': [len([os.path.join(path+'/test/PNEUMONIA', filename) \n",
    "                        for filename in os.listdir(path+'/test/PNEUMONIA')])]})\n",
    "\n",
    "sns.barplot(data=test_samplesize).set_title('Test Set Data Inbalance', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99033c-e60b-44b6-8583-a28d460c819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(batch):\n",
    "        images,labels = batch\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        out = model(images)                                      \n",
    "        loss = F.cross_entropy(out, labels)                    \n",
    "        acc,preds = accuracy(out, labels)                       \n",
    "        \n",
    "        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n",
    "                'preds':preds.detach(), 'labels':labels.detach()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a49a48-db57-4dee-8a8c-27724279fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    " def test_prediction(outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()           \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()             \n",
    "        # combine predictions\n",
    "        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n",
    "        # combine labels\n",
    "        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n",
    "        \n",
    "        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n",
    "                'test_preds': batch_preds, 'test_labels': batch_labels}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0551c-37a2-431e-84c1-32c1acfca182",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_predict(model, test_loader):\n",
    "    model.eval()\n",
    "    # perform testing for each batch\n",
    "    outputs = [validation_step(batch) for batch in test_loader] \n",
    "    results = test_prediction(outputs)                          \n",
    "    print('test_loss: {:.4f}, test_acc: {:.4f}'\n",
    "          .format(results['test_loss'], results['test_acc']))\n",
    "    \n",
    "    return results['test_preds'], results['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7038c-41cb-4293-af65-1a033a21cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = ImageFolder(path+'/test', \n",
    "                           transform=transform.Compose([transform.Resize(255),\n",
    "                                                 transform.CenterCrop(224),                                                              \n",
    "                                                 transform.ToTensor(),\n",
    "                                                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bb379-e9ac-4681-b814-566e8e591a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(testset, batch_size=256)\n",
    "model.to(device)\n",
    "preds,labels = test_predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfc496-f828-4d67-84bf-783412edf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm  = confusion_matrix(labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.xlabel('Predicted Label',fontsize=18)\n",
    "plt.ylabel('True Label',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcdf7c-0223-4f79-bbc4-5d1a26d74bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Performance Metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (np.array(preds) == np.array(labels)).sum() / len(preds)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\"Accuracy of the model is {:.2f}\".format(accuracy))\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "print(\"F1 Score of the model is {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285888c8-3d49-4ee2-9fa3-87fd07ce3265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 5 normal and 5 pneumonia images indices\n",
    "idxs = torch.tensor(np.append(np.arange(start=0, stop=5, step=1), \n",
    "                             np.arange(start=500, stop=505, step=1))) \n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,14))\n",
    "\n",
    "for c,i in enumerate(idxs):\n",
    "    img_tensor, label = testset[i]\n",
    "    ax[c//5][c%5].imshow(img_tensor[0,:,:], cmap='gray')\n",
    "    ax[c//5][c%5].set_title('Label: {}\\nPrediction: {}'\n",
    "                            .format(testset.classes[label], \n",
    "                                    testset.classes[preds[i]]),\n",
    "                            fontsize=25)\n",
    "    ax[c//5][c%5].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e516df-7777-4164-8c13-48bf8ae59766",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,12), ncols=2, nrows=4)\n",
    "\n",
    "for row in range(4):\n",
    "    img,label = testset[row]\n",
    "    pred = torch.exp(model(img.to(device).unsqueeze(0)))\n",
    "    class_name = ['NORMAL', 'PNEUMONIA']\n",
    "    classes = np.array(class_name)\n",
    "    pred = pred.cpu().data.numpy().squeeze()\n",
    "    ax[row][0].imshow(img.permute(1, 2, 0))\n",
    "    ax[row][0].set_title('Real : {}'.format(class_name[label]))\n",
    "    ax[row][0].axis('off')\n",
    "    ax[row][1].barh(classes, pred)\n",
    "    ax[row][1].set_aspect(0.1)\n",
    "    ax[row][1].set_yticks(classes)\n",
    "    ax[row][1].set_yticklabels(classes)\n",
    "    ax[row][1].set_title('Predicted Class')\n",
    "    ax[row][1].set_xlim(0, 1.)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cbac36-b3b4-41bf-86ae-87bf5a1712db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
